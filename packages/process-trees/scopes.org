#+TITLE:scopes

* the idea

*UPDATE*: this is about (sub)systems.  Which among other things is a scope.
Particularly, a subsystem provides a way for (contingent) processes to name
things freely while still comprising a larger system where each thing has a
unique, non-conflicting name.

In yet other words, a subsystem is a live namespace.

Can something be a live namespace without being a subsystem?  If it is not a
creator of processes.  Are there such things?  It depends on what you mean by
live namespace.  Something like the multiwave (which is a kind of port resolver)
does create (or at least provide) subscribables corresponding to a set of names,
and minting them (for later binding) if necessary.

A knowledge-based runtime will require a notion of "scopes" even for the
simplest cases.

What is a scope?

In RDF terms, you can think of a scope as a named graph with a special
entailment rule applied.  This entailment rule lets you state that graph A
entails graph B.  The effect of this is that all facts that are true in B are
true in A.

But in not-RDF terms, you can think of a scope as a namespace.  What
distinguishes the things in a scope is that they have a common /owner/, and by
extension a common provenance.

Note that if all sources are monotonic (increasing only), then constituents can
be comingled without the need for scopes (though note that there may be no way
to track the provenance of facts).  If a source may /stop/ contributing a
particular item, scopes provide a way to isolate each set of contributions so
that multiple contributors can contribute the same fact independently.

An outcome of scopes /should/ be that there are certain things which can never
collide, but note that this contradicts the previous point (that multiple scopes
can refer to "the same" fact).

Scopes become useful only if they partition a system into exclusive subsystems
(in a way that is non-overlapping), where the boundaries represent lines of
communication.

* entailment

A subsystem /entails/ its constituents.

A subsystem acts like a claim store that entails the claims of those subsystems
within its scope.


* composition

Subsystem can be implemented in "branch" and "leaf" ways.

It must be possible to create branch types that act as "components," that is,
systems of other things that can act as though self-contained.

While it must be possible to "chunk" components (treat them as a unit), it must
also be possible to inspect them when they use sub processes.

On the face of it, it would appear that a hard hierarchy of scopes would be too
constraining for many practical purposes.  The difference here is that the
system supports arbitrary lines of communication between nodes.  It is true that
values passed along those lines may cause changes in the process graph elsewhere
in the tree, but such changes are always done by the immediate parent of the
processes (if they choose to do so).

Creating a "component" MUST NOT require creating a subclass.  It must be
possible to do using data only.

* chunking and oblique communication

The fact that communication lines may be set up between any two locations in the
system breaks encapsulation.  We're considering this okay, part of the tradeoff.

More than that, though... I guess is the following channel issue.

* point-to-point communication

The system provides a way to specify point-to-point connections between
communication points (ports, or whatever you want to call them).

The requirement is that it will maintain all of the specified connections even
as actual backing things come and go.  If you say that =A= listens to =B=, the
system will ensure that all messages to =A= are forwarded to =B= whenever =A= and =B=
exist.  Actual processes at =A= and =B= may come and go at any time.

* IPC and buffered communication

So far, the discussion of IPC has centered on reactive (event-driven) dataflow.
This allows us to make certain assumptions, particularly that
- message passing is non-blocking
- message receipt is non-destructive to the sender

However, there are situations where this doesn't work.

When a data-processing step is asynchronous, a node cannot continue to receive
messages and still guarantee a consistent output order.  There may also be a
limit on the number of requests that a thing can concurrently handle.

Buffering is the typical way to handle this.

However, buffers have limits.  When inputs are faster than outputs, one option
is to selectively drop values when the buffer is at its configured capacity.

However, this is not always acceptable, either.  In such cases, nodes should be
able to /block writes/.

Combined with the ability of an upstream writer to non-destructively query
whether a channel is able to accept a new value, systems offer a way to signal
backpressure.

These properties (buffering and blocking) have many consequences for 

* invariants

A scope acts as a namespace.

Every scope itself lives in a context.

Each scope may contain zero or more scopes.

Each scope contained by a scope has a name.

Is a scope itself a process?  Yes.

Who decides what change take place in a scope?

The owner.  The scope "itself," which is a process.  That's the whole point.

Don't you want scopes to prevent reference leakage?  Yes, I'm talking about
encapsulation.

There are two kinds of scopes: reified and reflected.

In a reified scope, child processes are driven by facts that are turned into
child processes.  In a reflected system, child processes are not determined as
such but created directly.

How can a reified subsystem be the child of a reflected subsystem, or vice
versa?

* subsystems

A subsystem is a process that can spawn other processes.

A subsystem MUST NOT leak references to the things it creates.

A subsystem MUST hide references to any underlying mechanims (same point as
above).

A subsystem MUST support non-monotonic, declarative, stream-based inter-process
communication:

- declarative :: using data-based descriptions (not concrete mechanisms)

- stream-based :: targeting a specific dataflow (stream & transform) interface

- non-monotonic :: communication channels can be added and removed

PROVISIONAL There are two disjunct types of subsystem:

- reified subsystem :: assertions drive the creating and updating of things
- reflected subsystem :: things drive the claims

** spawn

Each thing spawned by a subsystem must have a unique name within that subsystem.

Does it know its name?
Does it know about its supersystem (containing system)?

* sketch

Interface or implementation?

Implementers would be anything that can't be composed from smaller bits.
Generally they will be wrappers for a built-in or third-party mechanism.

There comes a time in the life of every subsystem when
- it is born
  - with certain fixed, invariant, portable (data-based) properties
- it finds out that a new thing has been created
- it decides to create a new thing
- it finds out that it's time to die
  - e.g. web socket closed
    - but does this mean you're *gone* or just in that state?
- it finds out that one of its children died
  - how does this work for reified systems?
    - can be expected?  considered an error?
    - can/should recreate the thing?
- it is asked (by its parent) to die
- it is asked to set up some IPC?
- the process "itself" has messages to broadcast?
- the process "itself" has ports become available?

* inter-process communication (IPC)

We have talked about inter-process communication (IPC) as a separate layer on
top of the spawn layer, subject to a different set of invariants.

If we think of processes as nodes and communication channels as (the exclusive
form of) edges in a dataflow, then we can say that without IPC, there is no
dataflow.  We can say that, although nodes are facts, and although edges would
also be facts (when they are present), that the dataflow cannot have a /state/
until there are edges to propagate values through it.  Ingresses may be an
exception to this.  An ingress can recieve values without there being an edge
connected to any other node.  In practice, though, most ingresses will be
implemented as streams, in which case a subscription (edge) /would/ be needed to
initiate activity.

What messaging can take place /outside/ of IPC?
- must be sufficient to support creation and destruction of processes

Do parents and children get comunication lines "for free" for that purpose?

The objective to avoid direct object references between systems supports the
notion that communication takes place through channels.

Note that IPC will require references between instances (at least for idiomatic
usage), and this subs/parent navigation is useful to see (when you have a way to
see it).

But won't some API's require direct references between instances?  i.e. there
are some methods that require an instance as an argument?  Outside of DOM, I
can't think of any offhand.

Spawn must be a direct, on-site operation.  (Sort of---even that can be mediated
through system if we have constructable descriptions).




** ports

We can consider that the endpoints of communication channels are associated with
- the process itself
- a (named) port associated with that process

It's possible to devise declarative IPC that targets either or both of those.

* questions

In a reflected system, isn't it possible for a process to die without its child
processes dying?  If so, could you maintain the "contingent" invariant by
reassigning it to an ancestor reified process (assuming the root is always one)?

Isn't it true that
- reify needs to be based around RDF @type
- reflect needs to be based around instance (class or @type)

So you can't really do both in the "same thing".

And why would you want to?

Can this be done through protocol implementations?

* decision log
** parent/child relationships are not edges as such

A relationship obtains between a subprocess and its children.  This relationship
can be thought of in various ways: ownership, contingency, entailment.

But these relationships are /not/ represented directly by facts in the KB.
Rather, they are implicit in the structure of the graph system.  Subsystems
function like named graphs which are entailed by their supersystems.
Information about these relationships is available and can in principle be used
as the basis for inferrable facts about, e.g. provenance.  However, such
information is not apparent in the projection of the graph.

Note that, since assertions made by a process are limited to the scope in which
they occur, this arrangement also makes it impossible for subsystems to assert
these parent-child relationships about other subsystems.  This is essential to
the invariant that subsystems retain exclusive control over their immediate
children.

** channels are processes

Even unbuffered channels (a.k.a. rendez-vous), which have to hang onto promises.

Channels also implement state machine, in a couple of ways.

Like streams, they can go unrecoverably into close/done/end/dead state.

But channels with fixed buffers can also go temporarily into blocking states:
- blocking write : when buffer is full (or no pending reader for unbuffered)
- blocking read : when buffer is empty (or no pending writer for unbuffered)

Those are mutually exclusive states.  They do become irrelevant when the thing
closes, so perhaps they don't really form a completely separate state machine.

#+begin_src dot :file fixed-buffer-channel-states.svg
digraph {
	label = "fixed-buffer channel"
	compound = true
	node [shape = circle width = "1.5" style = filled]
	
	subgraph cluster_open {
		style="rounded"
		{
			rank = same
			empty [
				   color = red
				   shape = doublecircle
				   label="empty -\nblocking\nread"]
			full [
				  color = darkgreen
				  label="full - \nblocking\nwrite"]
		}
		readable_writable [color = yellow label = "readable\n&\nwritable"]
	
		empty -> full [label = "+, count = size"]
		empty -> readable_writable [label = "+"]
		full -> empty [label = "-, count = 0"]
		full -> readable_writable [label = "-"]
		readable_writable -> empty [label = "-, count = 0"]
		readable_writable -> full [label = "+ count = size"]
		readable_writable -> readable_writable [label = "+"]
		readable_writable -> readable_writable [label = "-"]
	}
	
	closed
	readable_writable -> closed [label="close" ltail="cluster_open"]
}
#+end_src

#+RESULTS:
[[file:fixed-buffer-channel-states.svg]]

** transforms are processes

Even though every subscription (in rstream) can support its own transducer,
allowing transforms in point-to-point IPC would undermine some of the invariants
we want to maintain (discussed elsewhere).

Transducers can be not only stateful but fully side-effecting in their own
right.  A transform must be implemented as a child process.  This allows special
transducers to be treated as subsystems where necessary.  In this respect, the
fact that it's "still just a transducer" is irrelevant, if not untrue.

It is still trivial to connect two points through a transform by adding a
(named) child process based on the transform and then adding the (anonymous)
point-to-point connections.

** ports are not first-class

Ports are just contingent processes.  They are addressed by name.

* ports

Suppose that we created a process around a "plain object."  We treat its methods
(function properties) as ports (assuming single arity), and we treat its value
properties as streams.  To support properties-as-streams where the keys are
known, we'd need to wrap the object using getters and setters.  If the keys are
not known /a priori/ then this can be accomplished by using a =Proxy=.

We see that an object can effectively provide an arbitrary set of "ports"
without /actually/ creating a new process for each one.  That is, a single
dispatcher can handle requests to all ports.

If communication takes place between ports, then ports need to be identifiable.

If we want to retain the ability to say A.listensTo.B (which we do), then said
ports need to be addressable via IRI's.

** port maps

The "device interface" in the MultiWave functions somewhat like this.

* state machines

Processes can behave like state machines in various ways.

State machines are a useful abstraction for chunking dynamic systems.

We distinguish between a state machine and a state machine spec.

A /state machine spec/ describes a space of discrete, identifiable states and
labeled transitions between them.

A /state machine/ is a thing that can be interpreted according to a state machine
spec.

States can be designated as terminal.  States with no outbound transitions may
be seen as implicitly terminal.  In an open system, however, it cannot be known
that later assertions will not define transitions from such states.  It is
therefore preferable to explicitly mark terminal states as such.

The possible space of state machines is itself extensive.  UML includes a
formalization of a state machine language that includes conditional and
composite structures, entry and exit events, and other extended features.

But at essence, a state machine spec is a labeled, directed graph.  Sound
familiar?

** state transition diagrams

Resources
- https://en.wikipedia.org/wiki/State_diagram
- https://www.cs.unc.edu/~stotts/145/CRC/state.html
- https://github.com/NimaGhaedsharafi/VAS
- https://www.cs.usfca.edu/~jbovet/vas.html (403)
- https://martin-thoma.com/how-to-draw-a-finite-state-machine/
- http://nifi.ir/ (blocked by firewall)

** all processes are state machines

All processes are mortal.

Even processes that do not die willfully, can be killed by external means.

Therefore, all processes can be seen as implementing at least a simple state
machine:

#+begin_src dot :file state-machine-live-dead.svg
digraph {
  rankdir = LR
  node [shape = circle]
  dead [shape = doublecircle]
  alive -> dead
  
}
#+end_src

#+RESULTS:
[[file:state-machine-live-dead.svg]]


** state machines and process lifecycle

If we can understand a thing in terms of a state machine spec, this knowledge
can be integrated to advantage into the thing's adapter.

Specifically, a process can synchronize its "death" event with its terminal
states.




* ports, IPC, and facts /versus/ values

Note that the object graph gives you an idea of (some of) the possible lines of
communication in a program.  Where this breaks down is that you don't know what
references are embedded in closures.  Opaque closures really complicate
everything in metaprogramming.  (Private fields will soon add to this
debasement.)

We propose a runtime knowledge base in order to produce software artifacts with
traits that are essential for humans.

The knowledge base is not an end in its own right.  That is, the knowledge base
does not need to be all-knowing.  Some facts belong in the knowledge base
because they are of immediate importance to humans.  Some facts act as mediators
of knowlege: they make it possible to locate other information that does not
need to be in the knowledge base at all times.  Some facts---such as low-level
implementation details---may be knowable in userland but are of no interest.
Such facts we allow to remain as they have always been, subterranean.

We consider a distinction between this first tier (facts belonging in the
knowledge base) and the second tier (facts that are merely reachable).  Arguably
this group includes facts implied by, e.g. ontological or other rules.  With the
help of a backward-chaining engine (which we haven't implemented yet), such
facts could be reachable without being materialized.

But that isn't exactly what I mean here.  Maybe this is the wrong way to state
it.  What I mean is the difference between "the dataflow" and "the data."

Since a model with open semantics can represent any kind of entity, I'm wary of
making "dataflow" first-class from the outset.  Nevertheless, since it is
already possible for /static/ RDF graphs to talk about arbitrary domains in fixed
terms, we may as well at least consider the domain of /dynamic/ entities
(including dynamic graphs themselves) as a specially relevant to the modeling of
runtime activity.  This requires us to adopt at least one fundamental construct
for describing such activity.  There's a good point here, but I'm not quite
hitting it.  Anyway, it's a sideline in this context.

The notion of systems and processes which communicate through message passing is
basic.  Dataflow graphs are a construct that trades arbitrary message passing
for something more organized.  This tradeoff strongly favors the human.  Is it
the /only/ such tradeoff?  Perhaps not, but in any case the difficulty is not with
static dataflow.

If dataflow graphs take us from the unwieldy prospect of arbitrary message
passing into a more tractable space, it's clear that we need to take the next
step to make /arbitrarily changing/ dataflow similarly more tractable.

So it's worth asking how dataflow graphs achieve this win.  Message passing
occurs between identifiable entities (processes, actors, whatever).  Arbitrary
message passing means that any actor can send a message to any other actor at
any time.  Taking the processes as its nodes, a dataflow graph says that
messages may only be passed along its edges, which are usually directed.  In all
non-trivial systems, this greatly constrains how processes may interact.  The
question of what can influence what, for example, can be answered by common
graph analysis tools.  With unconstrained communication, such questions are
unanswerable.  Likewise, clustering algorithms can be used to identify
subsystems, etc.  Not to mention that graphs can be visualized in various ways.
Dataflow graphs "improve on" the general message passing situation by vastly
reducing the space of possibilities, and doing so in a way that is congruent
with a familiar and well-studied construct.

Now for the question of changes.  I downloaded a bunch of papers about dynamic
graph algorithms.  I haven't read them.  Though I'd note that they weren't about
dynamic graph /models/.  I suspect that most of the literature is in the realm of
dynamic graphs that simply report their state, rather than models that describe
how the graph changes.  Rather than stopping to read these papers, in any case,
I'm going to think through the problem as I see it.

Having said that, I should also note that /parts/ of... wait.  I was going to say
that parts of the dataflow graph in a system will be merely reflected rather
than reified.  This is true of nodes (think websocket clients), but I'm not sure
that it's true of edges.  All "wiring" between processes should well be able to
go through the system.

Going back to the point earlier, we can say that the dataflow graph (i.e. lines
of communication), being a set of facts essential to the system.

So yeah I forgot about this.  Over the summer I took the position that the
question of whether a fact belonged in the knowledge base was equivalent to the
question of whether it would need to be included for the purpose of transporting
the model.  This itself begs the question somewhat, because you can define what
is "essential" to the the model in different ways.  Sometimes a model's essence
is independent of its particular state.  But you can imagine cases in which you
can't convey the thing separately from the "transient" state of its processes.

Yet another way to distinguish the dataflow from the data is by rate of change:
we assume that the rate of dataflow is greater than the rate of change in the
dataflow structure itself.  It would seem in these cases that the graph is
failing at its intended purpose, though I haven't put my finger on exactly how.

Somewhat further to the earlier point about the "essence" of the model, we could
say that the dataflow's properties are asserted--- that they are "spoken"
somehow, while the model says nothing about the values.  The space of values is
infinite and generally orthogonal to the communication structure.

But the point here is that the values are not /always/ orthogonal to the
structure.  That is, changes in a dynamic dataflow /must/ be driven by the values
in the dataflow itself (or at least in /some/ dataflow), since the structure
itself is unchanging.

We are talking about a relationship between values and the /next/ state of the
graph.

Moving from open communication to a dataflow graph called for the introduction
of a new concept: lines of communication.

Moving from a graph that changes completely unpredictably to a graph that
changes more predictably must also call for the introuction of a new concept.

Suppose that you view the live (and unconstrained) communication taking place
among a set of actors.  This communication will insinuate a graph.  In practice,
the edges of the graph will be sparse.  That is, there will be pairs of nodes
that simply never communicate directly.  It is essentially the omission of these
potential edges that makes the explicit graph more readable and more telling
than the (dense) graph of /possible/ communication.

So let us consider the space of /possible/ changes to a graph, i.e. all possible
next graphs (next message send, in other example).  Unlike with the
communication channels, we don't have a natural bound on the set of ultimate
possibilities.  In that case, we reach a fix point when all possible edges have
been identified.

But suppose that we only consider the space of possibilities for a single
operation.  In terms of processes (nodes), we can either add a node or remove a
node.  This means that there are 2N possibilities for the next graph where N is
the number of nodes prior to the operation.

...continue

** communication

Leaving aside the question of representing dynamism, there remains the matter of
communication.

Suppose that all IPC lines may be considered as point-to-point wires (I want to
reserve the term "channels" for CSP usage) and can thus be described using from
and to identifiers.

We introduce the notion of a /port/.  A port is essentially a subscription.  It's
a process from which you can read values, and to which you can write values.

Like other processes in a system, ports are identifiable by way of their
location in the subsystem hierarchy.

We may talk about a port as "belonging to" its containing subsystem.  We may say
the same of other such process.  But ports are special in that they can be
addressed for IPC purposes.  So we come to the matter of, what /isn't/ a port?
And since those things can also be addressed, what can one do with such
addresses, and how can we tell the difference?

Take a websocket client for example.  A websocket client entails two ports.

Suppose that we have a subsystem located at =/users/user1=.

Now suppose that the =user1= process introduces a web socket client and calls it
=chat=.

Note that =chat= is itself a process.

By the above definition, the two communication ports entailed by the =chat=
process would have to be named.

It might be more intuitive to suppose that you could write directly to =chat= to
send messages and read directly from =chat= to listen to messages.

But we must point out several things here.

1. it may be necessary to communicate with the =chat= process itself.  In
   particular to send a message saying that it should be closed.
2. the =chat= process may emit information other than the messages, particularly
   =error= messages
3. there is nothing to stop us from writing directly to the chat's input or
   reading from its output.  This is just the way that subscriptions work and it
   can be useful for various reasons (e.g. to simulate messages, or monitor
   output)
4. as an implementation matter, the message ingress will likely be a stream
   source, meaning that an event listener will not be created until the port has
   at least one subscriber.  It is therefore possible to send output messages
   without creating a message listener.  In other words, they're two different
   things.

Therefore, it is necessary to name the incoming and outgoing message channels.

But more than that---is it necessary to target =next= within the port?

* idea: message output port

Like a logging output.  Something you can use generally on processes.  But from
where?  Like, it hijacks console.log?

* observation: KB and subsystems

In the current proposal, every subsystem functions like a named graph and in
which the root claim store is therefore derivative.

As such, every subsystem /could/ be serviced by a claim store mechanism.

However, I expect that most subsystems will not need to be treated like an
independent claim store most of the time.

This starts to speak to the question of how to bridge this divide between the
parts of the system that rely on a KB versus those that don't.  The latter are
"closer to the metal," and although it should be possible to use a KB-based
system to view and interact with them, they can also be used independently
through the native platform interfaces.

In fact, this implies that /most/ of the work takes place without a KB dependency.

* open questions

** DONE Why do we need the notion of ports?
- State "DONE"       from              [2019-11-13 Wed 22:00]

*UPDATE*: we don't need the notion of ports.

When we talk about communication between processes, we first note that messages
can take all shapes and sizes.  That remains the case even if we strive to keep
direct references to other processes out of message streams.

When we talk about communication between two things, we ultimately use
identifiers.  We may express what we mean in terms of patterns or queries, but
these must ultimately be resolved to identifiers, which we can always use
directly.

The final, unambiguous global identifier of a thing in a system is based on its
location in the process tree.  We may think of the process tree as an entailment
tree.  All things known to the system are in this tree somewhere.

(This can clearly work, especially if the system provides resolution mechanisms
for other types of identification schemes.  The only thing that bugs me about it
is that the resulting identifiers are themselves so "situated."  I say that they
are semantically consistent, yet it seems unlikely that they will be meaningful
once e.g. bootstrap & root processes are included.  We'll see.)

Going back to the point about message shape and size.  Some messages may look
like the kind that are sent to interceptor buses, which include a message type
and payload.  Such messages could be considered isomorphic with multiple streams
that are connected to ports (or even subprocesses) corresponding to each message
type.  It should be trivial to construct nodes that transform from one type to
the other.

It's clear that processes need /at least/ one... inlet where they can recieve
messages.  Suppose that to keep things simple we said that they could have
/exactly/ one such inlet.  In that case, the kind of "mutli-port" messaging scheme
just described could be achieved using interceptors-style messages (or an
equivalent object-based approach).  However, taking the opposite approach---that
the process can receive the messages independently from multiple
streams---requires that we introduce a first-class construct that allows us to
represent and support multiple named inlets.  This has implications in a number
of places:
- how we describe IPC connections
- the minimal process interface

That said, /not/ introducing first-class ports means that we must use existing
constructs to support the described usage.  The role of pseudo-ports would then
fall to subprocesses, which are named, addressable constructs that can act as
message targets (via their one inlet).

When would that approach be a problem?  You want to avoid unnecessary lookup and
dispatching in cases where the most obvious thing is to connect a line
"directly" to e.g. a method call.  Again, it's trivial to transform a value into
the necesary form.

What about messages targeting the process "itself"?  Is there a message protocol
that we expect to be recognized by all processes?



** DONE How do you address processes "directly"?

- State "DONE"       from              [2019-11-13 Wed 23:15]
*UPDATE*: There is no generally-available process-qua-process.

Meaning, how do you talk to a process /qua/ process, i.e. in terms of its
lifecycle.  Such messages would be handled through its process interface.

What messages do you have in mind?  Die?  But no one can say that to the process
except for the parent.

What about a transducer with early termination?

That will end the subscription, but do we really want the default behavior of
bubbling this up to other subscriptions?  I don't have a real visceral sense of
what that (or the alternative) is like.





** are "ingress" and "egress" first-class?

** What is the process lifecycle?

** Can process lifecycle take advantage of stream termination semantics?

Especially since this is integrated with both rstream and csp.

** Tell me more about how things can be one or more state machines

** How would blocking be represented?

It must have to do with process state.



** what does it look like when "free" processes update based on messages?

This turned into a question about collections.

** how would "collection processes" work?

All "changeable" values are modeled as reactive variables, which are implemented
as processes.  Using them is very similar to using any other dataflow.  You
subscribe to the value, and the channel emits a message every time there's a new
value.

They are (they must be) stateful processes that can respond to messages asking
for direct mutations, not always asserting a whole new collection, right?

Do such processes not have e.g. error, done, or the putative "message" channel?

Are those channels available at sub paths?

Do you need to attach to "next" to get the value itself?

You could send add/remove messages by key (for keyed collections) or by value
(for value-keyed collections).

Does this not break down for fact stores?  That is, don't you have to deal with
the contents of claims stores all at once?  It's the same problem that exists in
the aggregate graph.  When someone says to "unassert" something, you don't know
who's saying that.  In particular, you don't know that multiple parties aren't
giving conflicting messages about whether a given fact should exist.  Remember,
"retract" is not the same thing as asserting a negative.

Be that as it may, you have to work with collections at some point, and if you
aren't making modifications, then how do you make composite things?

An alternative---one I considered over the summer but never implemented---was to
define collections in terms of persistent set operations.  So if you want
collection =A= to include item =x=, you can create a value stream with the value =x=
and assert that =A= contains it.  These assertions are bundled (by a driver that
handles the =includes= property) such that the resulting value enumerates all
those things.  The same can be done for =isSupersetOf= to subsume entire
collections.

However, that approach depends on a full KB implementation.

In the meantime, I don't see any technical reason why mutable collection
(ad-hoc, non-computed, whatever) collections can't be implemented as stateful
things that respond to messages and the devil take any inconsistencies.


** DONE If an IPC edge points to a path in the subsystem tree, what does it do?
- State "DONE"       from              [2019-11-13 Wed 23:17]

*UPDATE*: it writes to that process's message inlet.

Let's say that we have the path =/app= which is the governor for all of the main
processes in a MultiWave UI app.  One of those child processes is
=/app/multiwave=, representing a MultiWave interface on the default host.

(I was using the example of =/devices/multiwave=, but on consideration I see no
reason why the /subprocess tree/ should be organized that way.)

So let's suppose that we want to bind something to the voltage reading.  You
would expect to write that like:

=X listensTo /app/multiwave/voltage=

You would expect this to forward the actual voltage values from the interface to
=X=, whatever that is.

And maybe that is what it would do.

Does that mean that voltage is a port?

What happens if that stream ends?  i.e. that process dies?

** DONE does persistent point-to-point communication mean that process death is meaningless?

- State "DONE"       from              [2019-11-13 Wed 23:20]
*UPDATE*: No.  P2P IPC is still in the realm of static dataflow.  Lifecycle is in
the dynamic realm.

We've said that a connection from =A= to =B= is maintained by the system regardless
of the existence or state of =A= and =B=.  i.e. that the line of communication is
not contingent.  This has the obvious advantage that you can treat it as an
invariant.  You don't have to worry about saying, "If =A= dies, please
re-establish this connection as and when =A= is available again," which is
probably what you want in the vast majority of cases.

This means that IPC as currently described exists at a level somehow "above"
that of the process lifecycles.

This is intuitive if you think about it like a patch cable.  A p2p spec says,
"plug this into that and leave it plugged in until I tell you otherwise."

Whatever's going on inside the machine, the line keeps those two points
connected.

This does not, however, mean that "process death is meaningless."

If you want to talk about transient things, there must be a different way to do
that.

** how do you model things that naturally have request-response semantics?

A synchronous example: here is a query desc, I want a triple store to give me
the process associated with it (meaning its results).

An asynchronous example: HTTP request

Can promises be subsumed into a model that allows us to talk about process
lifecycle?  (i.e. like a process that completes when it resolves ("settles") one
way or the other). (moved to adapters/promise.ts)

I would start by saying that most things that we'd now treat as request-response
can be reformulated to be expressed in terms of streams and, where necessary,
state machines.

For the query example, suppose that you have a triple store =K=.

Any process can produce a (data-based) query description /q/.

It's easy to suppose that we send =K= a message containing /q/.

=K= might react by reifying a process =Q= that implements the query /q/.

But the sender cannot tell =K= what the result should be called.  So how would it
later be addressed?  We can't beg the question by supposing that =K= will respond
with the name of =Q=.  The objective is not just to avoid reference leakage, but
also to avoid request-response flows.

I would contend that messaging is /not a good way/ to accomplish this.  Messaging
still comes from the imperative world.  What you really want is to /assert/ that
the query exists and reference it by some name where it will be when it's ready.

The problem in this case is that
- the requesting process (let's call it =R=) cannot make assertions about what =K=
  entails
- but we also cannot make =R= entail =Q= because it is inherently contingent on =K=.
  Indeed, =R= should not have access to =K= to create the query.

Would it matter if =K= were an ancestor of =R=?  What if descendant processes were
able to influence the composition of processes in the same superscope?  As
opposed to oblique processes.  I don't see why such exceptions should be made,
though.

Something's not right here.

The declarative approach is to say that, as long as =R= is entailed by =G= (which
let's call the root graph, where the reification rules are in effect), then a
query asserted by =R= to be associated (somehow) with =K=, then the query should be
reified, and any alias associated with it can be used by =R= (or, theoretically,
other processes).  It seems the missing piece is in that association: how would
=R= assert that /q/ is to be connected with =K=?

It would be easy to say that the association is made via a simple fact.  But
this would be exactly the kind of fact that it should not be possible for
processes to assert about other processes, right?

I may be confusing this kind of association with directly asserting the
parent-child relationship.  This is about a specific kind of fact that only
/indirectly/ asserts the existence of a process.

If the fact thus asserted can bubble into =K='s scope, then =K= can decide "on its
own" to reify /q/.  But this doesn't make sense, either, because there is no
reason that =R= would be (or need be) with =K='s own scope.

(In the specific case of a knowledge base, it may in fact be that most processes
reside under its scope.  But this is just an example and the same questions
apply to other types of process.)

Another possibility is that "the system" is responsible for all of the
reification, where "the system" is the scope at which reification is applied.
Indeed, this would seem to be necessary.  Consider that a consistent reification
can only be done at the level where all of the relevant facts are known.  For
example, if you have a scope =/A= that is asserting a fact about resource =/A/B= and
a scope =/P/Q= that is also asserting a fact about =/A/B=, then it is not possible
for =/A= to reify =/A/B= using only its aggregated facts.  I mean, it's possible for
=/A= to reify it, it will just not be consistent with the global description of
the resource.

This sounds like quite a departure in some sense from the direction things have
been going (with these isolated adapters and mechanisms).  However, it has been
assumed that IPC would be centrally managed, since it can be used to connect any
two points.  So it is already assumed that the system has (or can get) access to
all of the things.

Now... I have supposed that it would be possible to attach reification at other
levels if you /wanted/ to.  If all resource management is being done centrally,
then it's not as clear how that would work.  But then again, it's not clear how
this would work, either.

At any rate, suppose that the system /does/ do all management centrally.  And the
adapters only know about their own thing and they report all reflected children
to the system immediately.  How would that solve the case in question?

It would be possible for =G= to reify /q/ against =K=.  The fact of /q/ remains entailed
by =R=.  What remains is
- whether the resulting =Q= is in =K='s scope
- how to make =Q= contingent on =K=

Unless the system somehow constructs the instance /through/ =K=.  It would be in
effect as if =K= did it.

** can a channel be seen as an async iterable? (from a reader's pov?)
